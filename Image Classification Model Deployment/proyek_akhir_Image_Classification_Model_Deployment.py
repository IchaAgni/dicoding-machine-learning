# -*- coding: utf-8 -*-
"""Proyek ketiga.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WtcCsS4F5sttMTRPU49PEBFloBl6YWAS

**Nama: Muhammad Al Fikri**

**Asal Instansi: STT Terpadu Nurul Fikri**

**Grup SIB: M04**

*Dataset yang digunakan:*  
https://www.kaggle.com/datasets/chetankv/dogs-cats-images

# Proses Klasifikasi Gambar Anjing dan Kucing

## Mengimpor Library yang Dibutuhkan
"""

from google.colab import drive
import zipfile, os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten
from keras.models import Sequential
import matplotlib.pyplot as plt
import numpy as np

"""## Mengimpor Dataset dari Google Drive"""

drive.mount('/content/drive')

"""## Melakukan Ekstraksi pada File zip"""

local_zip = '/content/drive/MyDrive/dataset/dogvscat.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content/')
zip_ref.close()

"""## Melakukan Splitting Data"""

base_dir = '/content/dataset'
train_dir = os.path.join(base_dir, 'training_set')
validation_dir = os.path.join(base_dir, 'test_set')

"""## Menampilkan Kelas dari train_dir dan validation_dir"""

os.listdir(train_dir)

os.listdir(validation_dir)

"""## Preprocessing Data"""

train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range = 40,
                    horizontal_flip = True,
                    shear_range=0.2,
                    zoom_range=0.2,
                    validation_split=0.2,
                    fill_mode = 'nearest')

train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size = (150, 150),
        batch_size = 32,
        class_mode = 'binary')

validation_datagen = ImageDataGenerator(
    rescale=1.0/255
)

validation_generator = validation_datagen.flow_from_directory(
        validation_dir,
        target_size = (150, 150),
        batch_size = 32, 
        class_mode = 'binary'
        )

"""## Membuat Model"""

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dropout(0.5),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

"""## Menampilkan Model Summary"""

model.summary()

"""## Menambahkan Optimizer"""

model.compile(loss='binary_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

"""## Menambahkan Fitur Callback"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.9 and logs.get('val_accuracy')>0.9):
      print("Akurasi minimum sudah tercapai (90%)")
      self.model.stop_training = True

callbacks = myCallback()

"""## Melakukan Proses Training Model"""

num_epochs = 50
history = model.fit(
      train_generator,
      epochs=num_epochs,
      validation_data=validation_generator,
      validation_steps=5,
      verbose=2,
      callbacks=[callbacks])

"""## Menampilkan Plot Accuracy"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title("Accuracy Model")
plt.xlabel("Accuracy")
plt.ylabel('Epoch')
plt.legend(['Train', 'Validation'],loc='lower right')
plt.show()

"""## Menampilkan Plot Loss"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Training','Validation' ],loc='upper right')
plt.show()

"""## Melakukan Prediksi Gambar"""

from google.colab import files
from keras.preprocessing import image
import matplotlib.image as mpimg

uploaded = files.upload()

for fn in uploaded.keys():
  path = fn 
  img = image.load_img(path, target_size =(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)


  print(fn)
  if classes[0,0]!=0:
    print('Dog')
  else:
    print('Cat')

uploaded = files.upload()

for fn in uploaded.keys():
  path = fn 
  img = image.load_img(path, target_size =(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)


  print(fn)
  if classes[0,0]!=0:
    print('Dog')
  else:
    print('Cat')

"""## Mengubah Model"""

export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

import pathlib
tflite_model_file = pathlib.Path('catvsdog.tflite')
tflite_model_file.write_bytes(tflite_model)